{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pokeData = []\n",
    "Atrbts = ['Name', 'Type1', 'Type2', 'HP' ,'Attack', 'Defense', 'SpAtk', 'SpDef', 'Speed', 'Generation', 'Legendary']\n",
    "with open('pokemon.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        Dict = {}\n",
    "        for i in range(len(Atrbts)):\n",
    "            if Atrbts[i] in ['HP' ,'Attack', 'Defense', 'SpAtk', 'SpDef', 'Speed', 'Generation']:\n",
    "                Dict[Atrbts[i]] = int(row[i + 1])\n",
    "            elif Atrbts[i] == 'Legendary':\n",
    "                Dict[Atrbts[i]] = bool(row[i + 1])\n",
    "            else:\n",
    "                Dict[Atrbts[i]] = row[i + 1]\n",
    "        pokeData.append(Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combats = []\n",
    "with open('combats.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        combats.append([int(row[0]) - 1, int(row[1]) - 1, int(row[2]) - 1])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_abs(data):\n",
    "    \n",
    "    pokeFir = data[0]\n",
    "    pokeSec = data[1]\n",
    "        \n",
    "    features = ['HP' ,'Attack', 'Defense', 'SpAtk', 'SpDef', 'Speed']\n",
    "    re = []\n",
    "    \n",
    "    for f in features:\n",
    "        re.append(pokeData[pokeFir][f] - pokeData[pokeSec][f])\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_rel(data):\n",
    "    \n",
    "    pokeFir = data[0]\n",
    "    pokeSec = data[1]\n",
    "        \n",
    "    features = ['HP' ,'Attack', 'Defense', 'SpAtk', 'SpDef', 'Speed']\n",
    "    re = []\n",
    "    \n",
    "    for f in features:\n",
    "        re.append((pokeData[pokeFir][f] - pokeData[pokeSec][f]) / pokeData[pokeSec][f])\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= log(1 + exp(-logit))\n",
    "        if not y[i]:\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "    return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0]*len(theta)\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        for k in range(len(theta)):\n",
    "            dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "            if not y[i]:\n",
    "                dl[k] -= X[i][k]\n",
    "    for k in range(len(theta)):\n",
    "        dl[k] -= lam*2*theta[k]\n",
    "    return numpy.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam, X_train, y_train):\n",
    "    theta_f, _, _ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X_train[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "    return theta_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "        \n",
    "    theta_f = train(1, X_train, y_train)\n",
    "    \n",
    "    print('classifier = logistic\\t training accuracy = ' + str(performance(theta_f, X_train, y_train)))\n",
    "    print('classifier = logistic\\taccuracy = ' + str(performance(theta_f, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svmClassifier(kerneltype, trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "        \n",
    "    clf = svm.SVC(kernel = kerneltype)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_train)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_train, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    print('classifier = svm '+ kerneltype + ' training' + '\\taccuracy = ' + str(accuracy))\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_test, predictions)]\n",
    "    #print(predictions[:20])\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    \n",
    "    print('classifier = svm '+ kerneltype + '\\taccuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors  \n",
    "import numpy as np \n",
    "\n",
    "def knnClassifier(trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "        \n",
    "    knn = neighbors.KNeighborsClassifier()  \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = knn.predict(X_train)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_train, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    print('classifier = knn\\t training accuracy = ' + str(accuracy))\n",
    "    \n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_test, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    \n",
    "    print('classifier = knn\\taccuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  \n",
    "     \n",
    "def nb(trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "            \n",
    "    clf = GaussianNB() \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_train)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_train, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    print('classifier = nb\\t training accuracy = ' + str(accuracy))\n",
    "    \n",
    "    predictions = clf.predict(X_test) \n",
    "    accuracy = [(a == b) for (a, b) in zip(y_test, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    \n",
    "    print('classifier = nb\\taccuracy = ' + str(accuracy))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "     \n",
    "def rf(trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "            \n",
    "    clf = RandomForestClassifier() \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_train)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_train, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    print('classifier = rf\\t training accuracy = ' + str(accuracy))\n",
    "    \n",
    "    predictions = clf.predict(X_test) \n",
    "    accuracy = [(a == b) for (a, b) in zip(y_test, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    \n",
    "    print('classifier = rf\\taccuracy = ' + str(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "     \n",
    "def dt(crit, maxDepth, trainData, testData, feat):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for d in trainData:\n",
    "        X_train.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for d in testData:\n",
    "        X_test.append(feat(d))\n",
    "        if d[2] == d[0]:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "            \n",
    "    clf = DecisionTreeClassifier(criterion = crit, random_state = 100, max_depth = maxDepth) \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = clf.predict(X_train)\n",
    "    accuracy = [(a == b) for (a, b) in zip(y_train, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    print('classifier = dt\\t training accuracy = ' + str(accuracy))\n",
    "    \n",
    "    predictions = clf.predict(X_test) \n",
    "    accuracy = [(a == b) for (a, b) in zip(y_test, predictions)]\n",
    "    accuracy = sum(accuracy) / len(accuracy)\n",
    "    \n",
    "    print('classifier = dt\\taccuracy = ' + str(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Steel', 'Grass', 'Ghost', 'Flying', 'Rock', 'Bug', 'Fire', 'Fighting', 'Ice', 'Fairy', 'Dark', 'Psychic', 'Normal', 'Water', 'Poison', 'Electric', 'Dragon', 'Ground'}\n",
      "{'', 'Steel', 'Grass', 'Ghost', 'Flying', 'Ice', 'Rock', 'Fighting', 'Fire', 'Bug', 'Fairy', 'Dark', 'Psychic', 'Normal', 'Water', 'Poison', 'Electric', 'Dragon', 'Ground'}\n"
     ]
    }
   ],
   "source": [
    "type1 = set()\n",
    "type2 = set()\n",
    "for d in pokeData:\n",
    "    type1.add(d['Type1'])\n",
    "    type2.add(d['Type2'])\n",
    "\n",
    "print(type1)\n",
    "print(type2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode 'Type1' and 'Type2'\n",
    "type1 = list(type1)\n",
    "type1Id = dict(zip(type1, range(len(type1))))\n",
    "\n",
    "type2 = list(type2)\n",
    "type2Id = dict(zip(type2, range(len(type2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use all features provided in the data\n",
    "# feature = (poke1_type1, poke2_type1, poke1_iflen, poke2_iflen, diff_HP, diff_Attack,...)\n",
    "def feat_com(data):\n",
    "    \n",
    "    pokeFir = data[0]\n",
    "    pokeSec = data[1]\n",
    "     \n",
    "    re = [type1Id[pokeData[pokeFir]['Type1']]]\n",
    "    re.append(type1Id[pokeData[pokeSec]['Type1']])\n",
    "    re.append(pokeData[pokeFir]['Legendary'])\n",
    "    re.append(pokeData[pokeSec]['Legendary'])\n",
    "    \n",
    "    features = ['HP', 'Attack', 'Defense', 'SpAtk', 'SpDef', 'Speed']   \n",
    "    for f in features:\n",
    "        re.append((pokeData[pokeFir][f] - pokeData[pokeSec][f])/ pokeData[pokeSec][f])\n",
    "        \n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of training set\n",
    "trainPercent = 0.8\n",
    "\n",
    "trainData = combats[:int(len(combats) * trainPercent)]\n",
    "testData = combats[int(len(combats) * trainPercent):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = logistic\t training accuracy = 0.889675\n",
      "classifier = logistic\taccuracy = 0.8939\n",
      "classifier = logistic\t training accuracy = 0.8883\n",
      "classifier = logistic\taccuracy = 0.8944\n",
      "classifier = logistic\t training accuracy = 0.85055\n",
      "classifier = logistic\taccuracy = 0.8555\n"
     ]
    }
   ],
   "source": [
    "logistic(trainData, testData, feat_abs)\n",
    "logistic(trainData, testData, feat_rel)\n",
    "logistic(trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = knn\t training accuracy = 0.930925\n",
      "classifier = knn\taccuracy = 0.9078\n",
      "classifier = knn\t training accuracy = 0.934175\n",
      "classifier = knn\taccuracy = 0.9085\n",
      "classifier = knn\t training accuracy = 0.91145\n",
      "classifier = knn\taccuracy = 0.867\n"
     ]
    }
   ],
   "source": [
    "knnClassifier(trainData, testData, feat_abs)\n",
    "knnClassifier(trainData, testData, feat_rel)\n",
    "knnClassifier(trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = nb\t training accuracy = 0.81505\n",
      "classifier = nb\taccuracy = 0.8214\n",
      "classifier = nb\t training accuracy = 0.670875\n",
      "classifier = nb\taccuracy = 0.6697\n",
      "classifier = nb\t training accuracy = 0.672\n",
      "classifier = nb\taccuracy = 0.6737\n"
     ]
    }
   ],
   "source": [
    "nb(trainData, testData, feat_abs)\n",
    "nb(trainData, testData, feat_rel)\n",
    "nb(trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = rf\t training accuracy = 0.994925\n",
      "classifier = rf\taccuracy = 0.9461\n",
      "classifier = rf\t training accuracy = 0.995175\n",
      "classifier = rf\taccuracy = 0.9548\n",
      "classifier = rf\t training accuracy = 0.9968\n",
      "classifier = rf\taccuracy = 0.9612\n"
     ]
    }
   ],
   "source": [
    "rf(trainData, testData, feat_abs)\n",
    "rf(trainData, testData, feat_rel)\n",
    "rf(trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = rf\t training accuracy = 0.94435\n",
      "classifier = rf\taccuracy = 0.9446\n",
      "classifier = rf\t training accuracy = 0.951575\n",
      "classifier = rf\taccuracy = 0.9527\n",
      "classifier = rf\t training accuracy = 0.951625\n",
      "classifier = rf\taccuracy = 0.9526\n"
     ]
    }
   ],
   "source": [
    "dt('gini', 5, trainData, testData, feat_abs)\n",
    "dt('gini', 5, trainData, testData, feat_rel)\n",
    "dt('gini', 5, trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = svm rbf training\taccuracy = 0.999875\n",
      "classifier = svm rbf\taccuracy = 0.5595\n",
      "classifier = svm rbf training\taccuracy = 0.9282\n",
      "classifier = svm rbf\taccuracy = 0.9295\n",
      "classifier = svm rbf training\taccuracy = 0.919375\n",
      "classifier = svm rbf\taccuracy = 0.9099\n"
     ]
    }
   ],
   "source": [
    "svmClassifier('rbf', trainData, testData, feat_abs)\n",
    "svmClassifier('rbf', trainData, testData, feat_rel)\n",
    "svmClassifier('rbf', trainData, testData, feat_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = logistic\t training accuracy = 0.8883\n",
      "classifier = logistic\taccuracy = 0.8944\n",
      "logistic: time = 6.621151999999995\n",
      "classifier = knn\t training accuracy = 0.934175\n",
      "classifier = knn\taccuracy = 0.9085\n",
      "knn: time = 1.8680870000000027\n",
      "classifier = nb\t training accuracy = 0.670875\n",
      "classifier = nb\taccuracy = 0.6697\n",
      "nb: time = 0.2963629999999853\n",
      "classifier = svm rbf training\taccuracy = 0.9282\n",
      "classifier = svm rbf\taccuracy = 0.9295\n",
      "svm: time = 25.234667\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "start = clock()\n",
    "logistic(trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('logistic: time = ' + str(finish - start))\n",
    "\n",
    "start = clock()\n",
    "knnClassifier(trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('knn: time = ' + str(finish - start))\n",
    "\n",
    "start = clock()\n",
    "nb(trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('nb: time = ' + str(finish - start))\n",
    "\n",
    "start = clock()\n",
    "svmClassifier('rbf', trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('svm: time = ' + str(finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier = rf\t training accuracy = 0.995225\n",
      "classifier = rf\taccuracy = 0.9554\n",
      "random forest: time = 0.960160999999971\n",
      "classifier = rf\t training accuracy = 0.951575\n",
      "classifier = rf\taccuracy = 0.9527\n",
      "decision tree: time = 0.33588399999996454\n"
     ]
    }
   ],
   "source": [
    "start = clock()\n",
    "rf(trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('random forest: time = ' + str(finish - start))\n",
    "\n",
    "start = clock()\n",
    "dt('gini', 5, trainData, testData, feat_rel)\n",
    "finish = clock()\n",
    "print('decision tree: time = ' + str(finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "total: 40000\n",
      "positive: 18841\n",
      "negative: 21159\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for d in trainData:\n",
    "    if d[2] == d[0]:\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)\n",
    "print('train set')\n",
    "print('total: ' + str(len(y_train)))\n",
    "print('positive: ' + str(sum(y_train)))\n",
    "print('negative: ' + str(len(y_train) - sum(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "total: 10000\n",
      "positive: 4760\n",
      "negative: 5240\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "for d in testData:\n",
    "    if d[2] == d[0]:\n",
    "        y_test.append(1)\n",
    "    else:\n",
    "        y_test.append(0)\n",
    "print('train set')\n",
    "print('total: ' + str(len(y_test)))\n",
    "print('positive: ' + str(sum(y_test)))\n",
    "print('negative: ' + str(len(y_test) - sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
